Fine-tuned Google's flan-t5 on a large-scale dialogue summarization dataset using techniques like LoRA and parameter-efficient fine-tuning, reducing inference errors by 20%.

